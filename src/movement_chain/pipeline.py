#!/usr/bin/env python3
"""
Movement Chain - Fusion Pipeline (èåˆ Pipeline)

å®Œæ•´çš„ è§†é¢‘ + IMU â†’ èåˆ â†’ Rerun â†’ AI åé¦ˆ æµæ°´çº¿ã€‚

ç”¨æ³•:
    # åŸºæœ¬ç”¨æ³•
    python pipeline.py --video swing.mp4 --imu swing.csv

    # æŒ‡å®šè¾“å‡ºç›®å½•
    python pipeline.py --video swing.mp4 --imu swing.csv --output output

    # å¯åŠ¨ Rerun Viewer
    python pipeline.py --video swing.mp4 --imu swing.csv --spawn-viewer

    # åªç”Ÿæˆ Rerun æ–‡ä»¶ï¼Œä¸å¯åŠ¨ Viewer
    python pipeline.py --video swing.mp4 --imu swing.csv --no-spawn

Author: Movement Chain AI Team
Date: 2025-01-15
"""

import argparse
import json
import sys
from dataclasses import asdict  # Used for vision_metrics_data serialization
from datetime import datetime
from pathlib import Path

from .ai_coach import AICoach, AICoachV2
from .imu_swing_analyzer import analyze_swing
from .rerun_visualizer import RERUN_AVAILABLE, RerunVisualizer
from .schemas import KinematicPrompt, KinematicPromptV2
from .sensor_fusion import SensorFusion
from .vision_analyzer import VisionAnalyzer


def run_pipeline(
    video_path: str,
    imu_path: str,
    output_dir: str = "output",
    spawn_viewer: bool = False,
    gyro_range: int = 2000,
    downsample_factor: int = 10,
    use_v2: bool = True,
    model_type: str = "heavy",
) -> KinematicPrompt | KinematicPromptV2:
    """
    è¿è¡Œå®Œæ•´çš„èåˆ Pipeline

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        imu_path: IMU CSV æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºæ ¹ç›®å½• (session å­ç›®å½•ä¼šè‡ªåŠ¨åˆ›å»º)
        spawn_viewer: æ˜¯å¦å¯åŠ¨ Rerun Viewer
        gyro_range: IMU é™€èºä»ªé‡ç¨‹ (250, 500, 1000, 2000)
        downsample_factor: Rerun é™é‡‡æ ·å› å­
        use_v2: æ˜¯å¦ä½¿ç”¨ V2 è¾“å‡ºæ ¼å¼ (é»˜è®¤ True)
        model_type: MediaPipe æ¨¡å‹ç±»å‹ ("heavy", "full", "lite")

    Returns:
        KinematicPromptV2 (use_v2=True) æˆ– KinematicPrompt (use_v2=False)

    Output Structure:
        output/
        â””â”€â”€ session_{timestamp}/
            â”œâ”€â”€ swing.rrd              (Rerun å¯è§†åŒ–)
            â”œâ”€â”€ kinematic_prompt.json  (AI è¾“å…¥)
            â”œâ”€â”€ imu/
            â”‚   â”œâ”€â”€ analysis.png       (IMU ç›¸ä½åˆ†æå›¾)
            â”‚   â””â”€â”€ report.json        (IMU è¯¦ç»†æŠ¥å‘Š)
            â””â”€â”€ vision/
                â””â”€â”€ metrics.json       (Vision æŒ‡æ ‡)
    """
    print("=" * 70)
    print("  Movement Chain - Fusion Pipeline")
    print("=" * 70)
    print()

    # ========================================
    # åˆ›å»º Session ç›®å½•ç»“æ„
    # ========================================
    session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    session_dir = Path(output_dir) / f"session_{session_id}"
    imu_dir = session_dir / "imu"
    vision_dir = session_dir / "vision"

    # åˆ›å»ºç›®å½•
    session_dir.mkdir(parents=True, exist_ok=True)
    imu_dir.mkdir(exist_ok=True)
    vision_dir.mkdir(exist_ok=True)

    print(f"  Session: {session_id}")
    print(f"  è¾“å‡ºç›®å½•: {session_dir}")
    print()

    # ========================================
    # Step 1: è§†é¢‘åˆ†æ (MediaPipe)
    # ========================================
    print("[Step 1/5] è§†é¢‘åˆ†æ (MediaPipe)")
    print(f"  æ¨¡å‹: {model_type}")
    print("-" * 70)

    vision_analyzer = VisionAnalyzer(model_type=model_type)
    vision_result = vision_analyzer.analyze_video(video_path)

    print(f"  âœ… æ£€æµ‹åˆ° {len(vision_result.frames)} å¸§")
    print(f"  âœ… Impact å¸§: {vision_result.impact_frame_idx}")

    # ä¿å­˜ Vision æŒ‡æ ‡
    vision_metrics_file = vision_dir / "metrics.json"
    vision_metrics_data = {
        "video_file": vision_result.video_file,
        "fps": vision_result.fps,
        "total_frames": vision_result.total_frames,
        "width": vision_result.width,
        "height": vision_result.height,
        "impact_frame_idx": vision_result.impact_frame_idx,
        "impact_confidence": vision_result.impact_confidence,
        "metrics": asdict(vision_result.metrics),
    }
    with open(vision_metrics_file, "w", encoding="utf-8") as f:
        json.dump(vision_metrics_data, f, indent=2, ensure_ascii=False)
    print(f"  âœ… Vision æŒ‡æ ‡: {vision_metrics_file.relative_to(session_dir)}")
    print()

    # ========================================
    # Step 2: IMU åˆ†æ
    # ========================================
    print("[Step 2/5] IMU åˆ†æ")
    print("-" * 70)

    imu_df, imu_phases, imu_metrics, imu_report = analyze_swing(
        filepath=imu_path,
        gyro_range=gyro_range,
        output_dir=str(imu_dir),  # ä¿å­˜ IMU åˆ†æå›¾è¡¨å’ŒæŠ¥å‘Š
        show_plot=False,
        auto_isolate=True,
    )

    print(f"  âœ… æ£€æµ‹åˆ° {len(imu_phases)} ä¸ªé˜¶æ®µ")
    print(f"  âœ… å³°å€¼è§’é€Ÿåº¦: {imu_metrics.peak_angular_velocity_dps:.0f}Â°/s")
    print("  âœ… IMU åˆ†æå›¾: imu/swing_analysis.png")
    print("  âœ… IMU æŠ¥å‘Š: imu/swing_report.json")
    print()

    # ========================================
    # Step 3: ä¼ æ„Ÿå™¨èåˆ
    # ========================================
    print("[Step 3/5] ä¼ æ„Ÿå™¨èåˆ")
    print("-" * 70)

    fusion = SensorFusion()
    fused_data = fusion.fuse(
        vision_result=vision_result,
        imu_df=imu_df,
        imu_phases=imu_phases,
        imu_metrics=imu_metrics,
        imu_report=imu_report,
    )

    print(f"  âœ… èåˆ {len(fused_data.frames)} å¸§")
    print(f"  âœ… æ—¶é—´åç§»: {fused_data.alignment_offset_ms:.1f}ms")
    print()

    # ========================================
    # Step 4: Rerun å¯è§†åŒ–
    # ========================================
    print("[Step 4/5] Rerun å¯è§†åŒ–")
    print("-" * 70)

    rerun_file = None
    rerun_relative_path = None
    if RERUN_AVAILABLE:
        visualizer = RerunVisualizer()
        rerun_file = str(session_dir / "swing.rrd")
        rerun_relative_path = "swing.rrd"

        visualizer.visualize_swing(
            fused_data=fused_data,
            output_path=rerun_file,
            spawn_viewer=spawn_viewer,
            downsample_factor=downsample_factor,
            video_path=video_path,
        )

        print(f"  âœ… Rerun æ–‡ä»¶: {rerun_relative_path}")
        if spawn_viewer:
            print("  âœ… Rerun Viewer å·²å¯åŠ¨")
    else:
        print("  âš ï¸ Rerun SDK æœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
        print("     è¿è¡Œ: pip install rerun-sdk>=0.20.0")

    print()

    # ========================================
    # Step 5: ç”Ÿæˆ AI åé¦ˆ
    # ========================================
    print("[Step 5/5] ç”Ÿæˆ AI Kinematic Prompt")
    print("-" * 70)

    if use_v2:
        # V2: çº¯æ•°æ® + å¸ƒå°”è§„åˆ™è§¦å‘
        coach = AICoachV2()
        kinematic_prompt = coach.generate_kinematic_prompt(
            fused_data=fused_data,
            visualization_file=rerun_relative_path,  # ä½¿ç”¨ç›¸å¯¹è·¯å¾„
        )
        prompt_file = session_dir / "kinematic_prompt.json"
    else:
        # V1: ä¼ ç»Ÿæ ¼å¼ (å¸¦æ–‡æœ¬å»ºè®®)
        coach = AICoach()
        kinematic_prompt = coach.generate_kinematic_prompt(
            fused_data=fused_data,
            visualization_file=rerun_relative_path,
        )
        prompt_file = session_dir / "kinematic_prompt.json"

    # ä¿å­˜ Kinematic Prompt
    kinematic_prompt.save(str(prompt_file))

    print("  âœ… Kinematic Prompt: kinematic_prompt.json")
    print()

    # ========================================
    # è¾“å‡ºæ€»ç»“
    # ========================================
    print("=" * 70)
    print("  Pipeline å®Œæˆ!")
    print("=" * 70)
    print()
    print(f"  Session ç›®å½•: {session_dir}")
    print()
    print("  ç”Ÿæˆæ–‡ä»¶:")
    print(f"    ğŸ“ {session_dir.name}/")
    print("    â”œâ”€â”€ kinematic_prompt.json  (AI è¾“å…¥)")
    if rerun_file:
        print("    â”œâ”€â”€ swing.rrd              (Rerun å¯è§†åŒ–)")
    print("    â”œâ”€â”€ imu/")
    print("    â”‚   â”œâ”€â”€ swing_analysis.png  (IMU ç›¸ä½åˆ†æå›¾)")
    print("    â”‚   â””â”€â”€ swing_report.json   (IMU è¯¦ç»†æŠ¥å‘Š)")
    print("    â””â”€â”€ vision/")
    print("        â””â”€â”€ metrics.json        (Vision æŒ‡æ ‡)")
    print()
    print("  æ•´ä½“è¯„ä¼°:")
    print(f"    - æ°´å¹³: {kinematic_prompt.overall_level}")

    if use_v2:
        # V2 è¾“å‡ºè§„åˆ™è§¦å‘ç»Ÿè®¡
        triggers = kinematic_prompt.rule_triggers
        print(f"    - è§„åˆ™è¯„ä¼°: {triggers.rules_triggered}/{triggers.rules_evaluated} è§¦å‘")
        if triggers.rules_triggered > 0:
            print("    - è§¦å‘çš„è§„åˆ™:")
            if triggers.tempo_ratio_outside_ideal:
                print("      â€¢ tempo_ratio_outside_ideal")
            if triggers.head_movement_excessive:
                print("      â€¢ head_movement_excessive")
            if triggers.x_factor_insufficient:
                print("      â€¢ x_factor_insufficient")
            if triggers.backswing_too_fast:
                print("      â€¢ backswing_too_fast")
            if triggers.downswing_too_slow:
                print("      â€¢ downswing_too_slow")
            if triggers.lead_arm_bent:
                print("      â€¢ lead_arm_bent")
            if triggers.velocity_below_amateur:
                print("      â€¢ velocity_below_amateur")
    else:
        # V1 è¾“å‡ºå…³é”®é—®é¢˜
        if kinematic_prompt.key_issues:
            print("    - ä¸»è¦é—®é¢˜:")
            for issue in kinematic_prompt.key_issues[:3]:
                print(f"      â€¢ {issue}")

    print()
    print("  ä¸‹ä¸€æ­¥:")
    if rerun_file:
        print(f"    1. è¿è¡Œ 'rerun {rerun_file}' æŸ¥çœ‹ 3D å¯è§†åŒ–")
    print("    2. å°† kinematic_prompt.json å†…å®¹ç²˜è´´åˆ° Claude/ChatGPT è·å–è¯¦ç»†åé¦ˆ")
    print("=" * 70)

    return kinematic_prompt


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(
        description="Movement Chain Fusion Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python pipeline.py --video swing.mp4 --imu swing.csv
  python pipeline.py --video swing.mp4 --imu swing.csv --spawn-viewer
  python pipeline.py --video swing.mp4 --imu swing.csv --output my_output
        """,
    )

    parser.add_argument(
        "--video",
        "-v",
        required=True,
        help="è§†é¢‘æ–‡ä»¶è·¯å¾„ (.mp4, .mov, .avi)",
    )

    parser.add_argument(
        "--imu",
        "-i",
        required=True,
        help="IMU CSV æ•°æ®æ–‡ä»¶è·¯å¾„",
    )

    parser.add_argument(
        "--output",
        "-o",
        default="output",
        help="è¾“å‡ºæ ¹ç›®å½• (é»˜è®¤: output, session å­ç›®å½•è‡ªåŠ¨åˆ›å»º)",
    )

    parser.add_argument(
        "--spawn-viewer",
        action="store_true",
        help="å¯åŠ¨ Rerun Viewer",
    )

    parser.add_argument(
        "--gyro-range",
        type=int,
        default=2000,
        choices=[250, 500, 1000, 2000],
        help="IMU é™€èºä»ªé‡ç¨‹ (é»˜è®¤: 2000)",
    )

    parser.add_argument(
        "--downsample",
        type=int,
        default=10,
        help="Rerun é™é‡‡æ ·å› å­ (é»˜è®¤: 10)",
    )

    parser.add_argument(
        "--v1",
        action="store_true",
        help="ä½¿ç”¨ V1 è¾“å‡ºæ ¼å¼ (å«æ–‡æœ¬å»ºè®®ï¼Œé»˜è®¤ä½¿ç”¨ V2 çº¯æ•°æ®æ ¼å¼)",
    )

    parser.add_argument(
        "--model",
        "-m",
        default="heavy",
        choices=["heavy", "full", "lite"],
        help="MediaPipe æ¨¡å‹: heavy (æœ€å‡†ç¡®, é»˜è®¤), full (å¹³è¡¡), lite (æœ€å¿«)",
    )

    args = parser.parse_args()

    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
    if not Path(args.video).exists():
        print(f"[ERROR] è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.video}")
        sys.exit(1)

    if not Path(args.imu).exists():
        print(f"[ERROR] IMU æ–‡ä»¶ä¸å­˜åœ¨: {args.imu}")
        sys.exit(1)

    try:
        run_pipeline(
            video_path=args.video,
            imu_path=args.imu,
            output_dir=args.output,
            spawn_viewer=args.spawn_viewer,
            gyro_range=args.gyro_range,
            downsample_factor=args.downsample,
            use_v2=not args.v1,
            model_type=args.model,
        )
    except Exception as e:
        print(f"\n[ERROR] Pipeline å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()
